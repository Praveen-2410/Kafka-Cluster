pipeline {
  agent any

  stages {
    stage('Load Environment Variables from .env') {
      steps {
        script {
          def envLines = readFile("${env.WORKSPACE}/Kafka-cluster/.env").split('\n')

          def getValue = { key ->
            def line = envLines.find { it.startsWith("${key}=") }
            return line ? line.split('=', 2)[1].trim() : null
          }

          // Load critical paths
          env.REMOTE_DIR = getValue("REMOTE_DIR")
          env.MULTI_NODE_REMOTE_DIR = getValue("MULTI_NODE_REMOTE_DIR")
          env.KAFKA_BASE_IMAGE = getValue("KAFKA_BASE_IMAGE")
          env.KAFKA_RELEASE = getValue("KAFKA_RELEASE")
          env.NEXUS_REPO = getValue("NEXUS_REPO")

          // Load broker IPs
          def broker1Ip = getValue("BROKER1_IP")
          def broker2Ip = getValue("BROKER2_IP")
          def broker3Ip = getValue("BROKER3_IP")

          // Cross checking the values
          if (!env.REMOTE_DIR || !env.MULTI_NODE_REMOTE_DIR || !env.KAFKA_BASE_IMAGE ||!broker1Ip || !broker2Ip || !broker3Ip || !env.KAFKA_RELEASE || !env.NEXUS_REPO)
          {
           error "One or more required variables are missing in the .env file!"
          }


          // Inject NODE variables
          env.NODE1 = "ec2-user@${broker1Ip}"
          env.NODE2 = "ec2-user@${broker2Ip}"
          env.NODE3 = "ec2-user@${broker3Ip}"

          echo """
          Loaded .env configuration:
          REMOTE_DIR = ${env.REMOTE_DIR}
          MULTI_NODE_REMOTE_DIR = ${env.MULTI_NODE_REMOTE_DIR}
          KAFKA_BASE_IMAGE = ${env.KAFKA_BASE_IMAGE}
          KAFKA_RELEASE = ${env.KAFKA_RELEASE}
          NEXUS_REPO = ${env.NEXUS_REPO}
          NODE1 = ${env.NODE1}
          NODE2 = ${env.NODE2}
          NODE3 = ${env.NODE3}
          """
        }
      }
    }

  
    stage('Generate Dynamic Tag') {
      steps {
        script {
          def timestamp = sh(script: "date +%Y%m%d%H%M", returnStdout: true).trim()
          env.IMAGE_TAG = "multi-node-npc-uae-kafka-${env.KAFKA_RELEASE}:${timestamp}"
        }
      }
    }

    stage('Inject Image Tag into File') {
      steps {
        dir("$MULTI_NODE_REMOTE_DIR") {
          script {
            def envVars = readFile("${env.WORKSPACE}/Kafka-cluster/.env").split('\n')
            def nexusHostLine = envVars.find { it.startsWith('NEXUS_HOST=') }
            def nexusHost = nexusHostLine?.split('=')[-1]?.trim()

            if (!nexusHost) {
              error "NEXUS_HOST not defined in .env file!"
            }

            env.IMAGE_FULL = "${nexusHost}/${env.NEXUS_REPO}/${env.IMAGE_TAG}"
            echo "Using image: ${env.IMAGE_FULL}"
            writeFile file: 'image-tag.txt', text: "${env.IMAGE_FULL}"
          }
        }
      }
    }

    stage('Build Docker Image') {
      steps {
        dir('Kafka-cluster') {
          sh 'docker build -t $(cat Multi-Node/image-tag.txt) .'
        }
      }
    }

    stage('Push Image to Nexus') {
      steps {
        dir("$MULTI_NODE_REMOTE_DIR") {
          withCredentials([usernamePassword(credentialsId: 'nexus-creds-alt', usernameVariable: 'NEXUS_USER', passwordVariable: 'NEXUS_PASS')]) {
            sh '''
              IMAGE=$(cat image-tag.txt)
              echo "$NEXUS_PASS" | docker login $(echo $IMAGE | cut -d/ -f1) -u "$NEXUS_USER" --password-stdin
              docker push $IMAGE
            '''
          }
        }
      }
    }

stage('Distribute Files to All Nodes') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        def nodes = [env.NODE1, env.NODE2, env.NODE3]
        for (node in nodes) {
          sh """
            ssh -o StrictHostKeyChecking=no ${node} '
              BASE_DIR="${REMOTE_DIR}"

              if [ -d "\$BASE_DIR" ]; then
                sudo chown -R 1000:1000 "\$BASE_DIR"
              fi

              mkdir -p "\$BASE_DIR/data"
              mkdir -p "\$BASE_DIR/config/certs"
              mkdir -p "\$BASE_DIR/config/client-properties"
              mkdir -p "\$BASE_DIR/scripts"
              chmod -R 755 "\$BASE_DIR"
            '

            # Copy core files
            scp -o StrictHostKeyChecking=no \
              Kafka-cluster/.env \
              $MULTI_NODE_REMOTE_DIR/image-tag.txt \
              $MULTI_NODE_REMOTE_DIR/docker-compose.yml.template \
              ${node}:${REMOTE_DIR}/

            # Copy server properties
            scp -o StrictHostKeyChecking=no \
              $MULTI_NODE_REMOTE_DIR/config/server.properties.template \
              ${node}:${REMOTE_DIR}/config/

            # Copy JAAS config files
            scp -o StrictHostKeyChecking=no \
              $MULTI_NODE_REMOTE_DIR/config/kafka_jaas.conf \
              $MULTI_NODE_REMOTE_DIR/config/kafka_admin_jaas.conf \
              ${node}:${REMOTE_DIR}/config/

            # Copy client SSL and admin props
            scp -o StrictHostKeyChecking=no \
              $MULTI_NODE_REMOTE_DIR/config/client-properties/client-ssl.properties \
              $MULTI_NODE_REMOTE_DIR/config/client-properties/admin.properties \
              ${node}:${REMOTE_DIR}/config/client-properties/

            # Copy certificate files
            scp -o StrictHostKeyChecking=no \
              $MULTI_NODE_REMOTE_DIR/config/multi-node-certs/*.p12 \
              ${node}:${REMOTE_DIR}/config/certs/

            # Copy scripts
            scp -o StrictHostKeyChecking=no \
              $MULTI_NODE_REMOTE_DIR/scripts/* \
              ${node}:${REMOTE_DIR}/scripts/

            # Set permissions
            ssh -o StrictHostKeyChecking=no ${node} '
              chmod 644 $REMOTE_DIR/config/certs/*.p12
              chmod +x $REMOTE_DIR/scripts/*.sh
            '
          """
        }
      }
    }
  }
}

    stage('Generate Configs (envsubst)') {
      steps {
        sshagent(credentials: ['ec2-ssh-key']) {
          sh "ssh -o StrictHostKeyChecking=no $NODE1 'cd $REMOTE_DIR && bash scripts/generate-configs.sh 1'"
          sh "ssh -o StrictHostKeyChecking=no $NODE2 'cd $REMOTE_DIR && bash scripts/generate-configs.sh 2'"
          sh "ssh -o StrictHostKeyChecking=no $NODE3 'cd $REMOTE_DIR && bash scripts/generate-configs.sh 3'"
        }
      }
    }

    stage('Cluster ID Setup + Format') {
      steps {
        sshagent(credentials: ['ec2-ssh-key']) {
          script {
            def nodes = [env.NODE1, env.NODE2, env.NODE3]
            def existingClusterIds = []

            for (node in nodes) {
              def id = sh(
                script: "ssh -o StrictHostKeyChecking=no $node 'grep cluster.id $REMOTE_DIR/data/meta.properties | cut -d= -f2 || true'",
                returnStdout: true
              ).trim()
              existingClusterIds.add(id ?: '')
            }

            def uniqueIds = existingClusterIds.findAll { it }.unique()
            if (uniqueIds.size() == 1) {
              echo "All brokers already formatted with cluster ID: ${uniqueIds[0]}"
              return
            }

            if (uniqueIds.size() > 1) {
              echo "Mismatched cluster IDs found. Backing up and cleaning..."
              def timestamp = sh(script: "date +%Y%m%d%H%M%S", returnStdout: true).trim()
              for (node in nodes) {
                sh "ssh -o StrictHostKeyChecking=no $node 'mkdir -p $REMOTE_DIR/data-dir-backup-${timestamp} && cp -r $REMOTE_DIR/data/* $REMOTE_DIR/data-dir-backup-${timestamp}/ && rm -rf $REMOTE_DIR/data/*'"
              }
            }

            sh 'docker pull apache/kafka:4.0.0'
            def clusterId = sh(script: "docker run --rm $KAFKA_BASE_IMAGE /opt/kafka/bin/kafka-storage.sh random-uuid", returnStdout: true).trim()
            echo "Generated Cluster ID: ${clusterId}"

            for (node in nodes) {
              sh """
                ssh -o StrictHostKeyChecking=no $node '
                  docker run --rm \
                    -v $REMOTE_DIR/config/server.properties:/opt/kafka/config/kraft/server.properties \
                    -v $REMOTE_DIR/data:/var/lib/kafka/data \
                    $KAFKA_BASE_IMAGE \
                    /opt/kafka/bin/kafka-storage.sh format -t $clusterId -c /opt/kafka/config/kraft/server.properties
                '
              """
            }
          }
        }
      }
    }

    stage('Start Kafka Containers') {
      steps {
        sshagent(credentials: ['ec2-ssh-key']) {
          withCredentials([usernamePassword(credentialsId: 'nexus-creds-alt', usernameVariable: 'NEXUS_USER', passwordVariable: 'NEXUS_PASS')]) {
            script {
              def nodes = [env.NODE1, env.NODE2, env.NODE3]
              for (node in nodes) {
                sh """#!/bin/bash
ssh -o StrictHostKeyChecking=no $node \\
NEXUS_USER='$NEXUS_USER' NEXUS_PASS='$NEXUS_PASS' bash -s <<'EOF'
set -e
IMAGE=\$(cat $REMOTE_DIR/image-tag.txt)
REGISTRY=\$(echo \$IMAGE | cut -d/ -f1)
echo "IMAGE: \$IMAGE"
echo "REGISTRY: \$REGISTRY"
echo "Logging in..."
echo "\$NEXUS_PASS" | docker login \$REGISTRY -u "\$NEXUS_USER" --password-stdin
cd $REMOTE_DIR
docker-compose -f docker-compose.yml up -d
EOF
"""
              }
            }
          }
        }
      }
    }

stage('Verify Initial Cluster Health') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        def maxRetries = 6
        def sleepSeconds = 10
        def success = false

        for (int i = 1; i <= maxRetries; i++) {
          echo "Attempt $i: Checking cluster health..."
          def result = sh(
            script: """
              ssh -o StrictHostKeyChecking=no $NODE1 '
                cd $REMOTE_DIR/scripts &&
                bash verify-cluster-health.sh
              '
            """,
            returnStatus: true
          )

          if (result == 0) {
            echo "Cluster is healthy."
            success = true
            break
          } else {
            echo "Cluster not healthy. Retrying in ${sleepSeconds}s..."
            sleep sleepSeconds
          }
        }

        if (!success) {
          error "Cluster did not become healthy after ${maxRetries} attempts!"
        }
      }
    }
  }
}

stage('Setup Admin User') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      sh """
        ssh -o StrictHostKeyChecking=no $NODE1 '
          cd $REMOTE_DIR/scripts &&
          bash setup-admin-user.sh
        '
      """
    }
  }
}

stage('Update super.users and Restart Brokers') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        def nodes = [env.NODE1, env.NODE2, env.NODE3]

        for (node in nodes) {
          sh """
            ssh -o StrictHostKeyChecking=no $node '
              # Update or insert super.users
              grep -q "^super.users=" $REMOTE_DIR/config/server.properties &&
              sed -i "s|^super.users=.*|super.users=User:admin;User:ANONYMOUS|" $REMOTE_DIR/config/server.properties ||
              echo "super.users=User:admin;User:ANONYMOUS" >> $REMOTE_DIR/config/server.properties

              # Update or insert allow.everyone.if.no.acl.found
              grep -q "^allow.everyone.if.no.acl.found=" $REMOTE_DIR/config/server.properties &&
              sed -i "s|^allow.everyone.if.no.acl.found=.*|allow.everyone.if.no.acl.found=false|" $REMOTE_DIR/config/server.properties ||
              echo "allow.everyone.if.no.acl.found=false" >> $REMOTE_DIR/config/server.properties

              # Restart brokers
              docker-compose -f $REMOTE_DIR/docker-compose.yml restart
            '
          """
        }
      }
    }
  }
}

stage('Re-verify Cluster Health Post-Restart') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        def maxRetries = 6
        def sleepSeconds = 10
        def success = false

        for (int i = 1; i <= maxRetries; i++) {
          echo "Attempt $i: Re-checking cluster health..."
          def result = sh(
            script: """
              ssh -o StrictHostKeyChecking=no $NODE1 '
                cd $REMOTE_DIR/scripts &&
                bash verify-cluster-health.sh
              '
            """,
            returnStatus: true
          )

          if (result == 0) {
            echo "Cluster is healthy after restart."
            success = true
            break
          } else {
            echo "Still unhealthy. Retrying in ${sleepSeconds}s..."
            sleep sleepSeconds
          }
        }

        if (!success) {
          error "Cluster not healthy after restart!"
        }
      }
    }
  }
}


stage('Create Users, Topics & ACLs') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        echo "Creating Kafka users, topics, and applying ACLs..."
        sh """
          ssh -o StrictHostKeyChecking=no $NODE1 '
            cd $REMOTE_DIR/scripts &&
            bash create_users_topic.sh
          '
        """
      }
    }
  }
}

stage('Cleanup Docker Images') {
  steps {
    sshagent(credentials: ['ec2-ssh-key']) {
      script {
        def nodes = [env.NODE1, env.NODE2, env.NODE3]

        echo "Cleaning up Jenkins build images (on Jenkins)..."
        sh '''
        cd Kafka-cluster/Multi-Node/scripts &&
        bash cleanup-jenkins-images.sh
        '''

        echo "Cleaning up old images in Nexus (retain 5)..."
        sh '''
          cd Kafka-cluster/Multi-Node/scripts &&
          bash cleanup-nexus-images.sh
        '''

        echo "Cleaning up old images on Kafka Nodes (retain 3 each)..."
        for (node in nodes) {
          sh """
            ssh -o StrictHostKeyChecking=no ${node} '
              cd $REMOTE_DIR/scripts &&
              bash cleanup-node-images.sh
            '
          """
        }
      }
    }
  }
}


stage('Deployment Summary') {
  steps {
    echo """
    Multi-Node Kafka Cluster Deployed Successfully
    """
  }
}
  }
}
